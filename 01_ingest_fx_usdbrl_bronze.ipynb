{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5c691f2-93ca-438e-a859-1b44d3157581",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 00_config_auth — autenticação via SAS guardado no Secret Scope (job-safe)\n",
    "\n",
    "# --- parâmetros (podem ser sobrescritos pelo Job via \"Parameters\") ---\n",
    "# Se preferir, edite aqui os valores padrão.\n",
    "try:\n",
    "    dbutils.widgets.get               # garante que widgets existem\n",
    "except:\n",
    "    pass\n",
    "\n",
    "def _wget(name, default):\n",
    "    try:\n",
    "        dbutils.widgets.text(name, default)\n",
    "    except:\n",
    "        # widget já existia\n",
    "        pass\n",
    "    return dbutils.widgets.get(name)\n",
    "\n",
    "acc   = _wget(\"storage_account\", \"stgflowdev001\")        # sem .dfs\n",
    "scope = _wget(\"secret_scope\",    \"meu_scope\")\n",
    "key   = _wget(\"secret_key\",      \"sas-stgflowdev001\")\n",
    "\n",
    "# --- lê o SAS do Secret Scope ---\n",
    "try:\n",
    "    sas_raw = dbutils.secrets.get(scope, key)\n",
    "except Exception as e:\n",
    "    raise Exception(\n",
    "        f\"[Auth] Falha ao ler secret: scope='{scope}', key='{key}'. \"\n",
    "        \"Verifique se o scope e a chave existem e se você tem permissão.\"\n",
    "    ) from e\n",
    "\n",
    "# --- limpa o SAS (remove quebras de linha/espaços e '?' inicial, se houver) ---\n",
    "sas = sas_raw.strip().replace(\"\\n\", \"\").replace(\"\\r\", \"\")\n",
    "if sas.startswith(\"?\"):\n",
    "    sas = sas[1:]\n",
    "\n",
    "if not sas.startswith(\"sv=\"):\n",
    "    raise ValueError(\n",
    "        \"[Auth] O valor do SAS não parece válido (não inicia com 'sv='). \"\n",
    "        \"Confira o segredo salvo no scope.\"\n",
    "    )\n",
    "\n",
    "# --- configura o Spark para usar SAS ---\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{acc}.dfs.core.windows.net\", \"SAS\")\n",
    "spark.conf.set(f\"fs.azure.sas.token.provider.type.{acc}.dfs.core.windows.net\",\n",
    "               \"org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.sas.fixed.token.{acc}.dfs.core.windows.net\", sas)\n",
    "\n",
    "# --- caminhos base (para usar nas células seguintes) ---\n",
    "bronze_base = f\"abfss://bronze@{acc}.dfs.core.windows.net\"\n",
    "silver_base = f\"abfss://silver@{acc}.dfs.core.windows.net\"\n",
    "gold_base   = f\"abfss://gold@{acc}.dfs.core.windows.net\"\n",
    "\n",
    "print(\"[Auth] OK — SAS aplicado e caminhos definidos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa16b9a7-6547-4947-9ee4-30dec87c82a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests, json, time\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "bronze_base       = f\"abfss://bronze@{acc}.dfs.core.windows.net\"\n",
    "bronze_delta_path = f\"{bronze_base}/fx_usdbrl/delta\"\n",
    "\n",
    "def fetch_usd_brl():\n",
    "    # 1) Frankfurter\n",
    "    try:\n",
    "        r = requests.get(\"https://api.frankfurter.app/latest?from=USD&to=BRL\", timeout=10)\n",
    "        r.raise_for_status()\n",
    "        p = r.json()\n",
    "        rate = float(p[\"rates\"][\"BRL\"])\n",
    "        ref_date = p.get(\"date\")\n",
    "        base = p.get(\"base\", \"USD\")\n",
    "        return {\"provider\":\"frankfurter\", \"base\":base, \"rate\":rate, \"ref_date\":ref_date, \"raw\":p}\n",
    "    except Exception:\n",
    "        pass\n",
    "    # 2) Open ER-API\n",
    "    r = requests.get(\"https://open.er-api.com/v6/latest/USD\", timeout=10)\n",
    "    r.raise_for_status()\n",
    "    p = r.json()\n",
    "    if p.get(\"result\") != \"success\":\n",
    "        raise ValueError(f\"Provider ER-API error: {p}\")\n",
    "    rate = float(p[\"rates\"][\"BRL\"])\n",
    "    ref_date = p.get(\"time_last_update_utc\")  # timestamp amigável\n",
    "    return {\"provider\":\"er-api\", \"base\":\"USD\", \"rate\":rate, \"ref_date\":ref_date, \"raw\":p}\n",
    "\n",
    "data = fetch_usd_brl()\n",
    "assert data[\"rate\"] > 0, \"Taxa inválida\"\n",
    "\n",
    "record = [{\n",
    "    \"provider\": data[\"provider\"],\n",
    "    \"base\":     data[\"base\"],\n",
    "    \"symbol\":   \"BRL\",\n",
    "    \"rate\":     data[\"rate\"],\n",
    "    \"ref_date\": data[\"ref_date\"],\n",
    "    \"ingestion_epoch\": int(time.time()),\n",
    "    \"raw_json\": json.dumps(data[\"raw\"], ensure_ascii=False)\n",
    "}]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"provider\", StringType(), True),\n",
    "    StructField(\"base\", StringType(), True),\n",
    "    StructField(\"symbol\", StringType(), True),\n",
    "    StructField(\"rate\", DoubleType(), True),\n",
    "    StructField(\"ref_date\", StringType(), True),\n",
    "    StructField(\"ingestion_epoch\", StringType(), True),\n",
    "    StructField(\"raw_json\", StringType(), True),\n",
    "])\n",
    "\n",
    "df_bronze = spark.createDataFrame(record, schema)\\\n",
    "                 .withColumn(\"ingestion_ts\", F.current_timestamp())\n",
    "\n",
    "(df_bronze\n",
    " .write\n",
    " .format(\"delta\")\n",
    " .mode(\"append\")\n",
    " .option('mergeSchema', 'true').save(bronze_delta_path)\n",
    ")\n",
    "\n",
    "display(spark.read.format(\"delta\").load(bronze_delta_path).orderBy(F.col(\"ingestion_ts\").desc()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0d7f5d3-f087-468d-bf8e-fa2dbdf1ea8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests, json, time\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType\n",
    "\n",
    "# 1) Consulta HTTP (sem token)\n",
    "url = \"https://api.exchangerate.host/latest?base=USD&symbols=BRL\"\n",
    "resp = requests.get(url, timeout=10)\n",
    "resp.raise_for_status()\n",
    "payload = resp.json()\n",
    "\n",
    "# 2) Extrai campos principais\n",
    "# Exemplo de payload:\n",
    "# {\"base\":\"USD\",\"date\":\"2025-08-19\",\"rates\":{\"BRL\":5.27}, \"success\":true}\n",
    "base = payload.get(\"base\")\n",
    "date = payload.get(\"date\")\n",
    "rate = float(payload.get(\"rates\", {}).get(\"BRL\", 0.0))\n",
    "ingestion_ts = int(time.time())\n",
    "\n",
    "record = [{\n",
    "    \"base\": base,\n",
    "    \"symbol\": \"BRL\",\n",
    "    \"rate\": rate,\n",
    "    \"ref_date\": date,          # data de referência informada pela API\n",
    "    \"ingestion_epoch\": ingestion_ts,  # carimbo da coleta\n",
    "    \"raw_json\": json.dumps(payload, ensure_ascii=False)  # trilha \"raw\"\n",
    "}]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"base\", StringType(), True),\n",
    "    StructField(\"symbol\", StringType(), True),\n",
    "    StructField(\"rate\", DoubleType(), True),\n",
    "    StructField(\"ref_date\", StringType(), True),\n",
    "    StructField(\"ingestion_epoch\",  StringType(), True),\n",
    "    StructField(\"raw_json\", StringType(), True),\n",
    "])\n",
    "\n",
    "df_bronze = spark.createDataFrame(record, schema)\\\n",
    "                 .withColumn(\"ingestion_ts\", F.current_timestamp())\n",
    "\n",
    "# 3) Escreve/Anexa em Delta (Bronze)\n",
    "(\n",
    "    df_bronze\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"append\")\n",
    "    .save(bronze_delta_path)\n",
    ")\n",
    "\n",
    "print(\"Bronze ✅ gravado em:\", bronze_delta_path)\n",
    "display(spark.read.format(\"delta\").load(bronze_delta_path).orderBy(F.col(\"ingestion_ts\").desc()))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_ingest_fx_usdbrl_bronze",
   "widgets": {
    "secret_key": {
     "currentValue": "sas-stgflowdev001",
     "nuid": "a870e4b7-0148-4335-84ae-e7a2e8fcc40a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "sas-stgflowdev001",
      "label": null,
      "name": "secret_key",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "sas-stgflowdev001",
      "label": null,
      "name": "secret_key",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "secret_scope": {
     "currentValue": "meu_scope",
     "nuid": "d14ff0da-d258-49d7-a477-c847be6880ee",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "meu_scope",
      "label": null,
      "name": "secret_scope",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "meu_scope",
      "label": null,
      "name": "secret_scope",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "storage_account": {
     "currentValue": "stgflowdev001",
     "nuid": "9393da42-f349-40d2-906b-259c9f07a5d5",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "stgflowdev001",
      "label": null,
      "name": "storage_account",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "stgflowdev001",
      "label": null,
      "name": "storage_account",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
